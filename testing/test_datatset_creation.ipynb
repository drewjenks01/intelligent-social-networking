{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download datatset of faces\n",
    "# if not os.path.exists('/content/ibug_300W_large_face_landmark_dataset'):\n",
    "#     !wget http://dlib.net/files/data/ibug_300W_large_face_landmark_dataset.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = os.listdir('testset')\n",
    "\n",
    "train_image_paths = []\n",
    "test_image_paths = []\n",
    "\n",
    "i=0\n",
    "while len(train_image_paths) < 150:\n",
    "    i+=1\n",
    "    # i into 3 digit number\n",
    "    if i < 10:\n",
    "        filename = f'image_000{i}'\n",
    "    elif i < 100:\n",
    "        filename = f'image_00{i}'\n",
    "    else:\n",
    "        filename = f'image_0{i}'\n",
    "\n",
    "    if filename+'.png' not in image_paths:\n",
    "        continue\n",
    "    \n",
    "    train_image_paths.append(os.path.join('testset', filename+'.png'))\n",
    "    test_image_paths.append(os.path.join('testset', filename+'_mirror.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 150)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_image_paths), len(test_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['testset/image_0001.png',\n",
       "  'testset/image_0002.png',\n",
       "  'testset/image_0003.png',\n",
       "  'testset/image_0004.png',\n",
       "  'testset/image_0005.png'],\n",
       " ['testset/image_0001_mirror.jpg',\n",
       "  'testset/image_0002_mirror.jpg',\n",
       "  'testset/image_0003_mirror.jpg',\n",
       "  'testset/image_0004_mirror.jpg',\n",
       "  'testset/image_0005_mirror.jpg'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image_paths[:5], test_image_paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewjenkins/anaconda3/envs/intelligent_sn/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from facial_detection.facial_detection import FacialDetection\n",
    "\n",
    "facial_detection = FacialDetection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:04,  2.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# facial embeddings -> image file name\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "train_data = {}\n",
    "ground_truth = {}\n",
    "train_embeddings = []\n",
    "test_embeddings = []\n",
    "\n",
    "for train_path, test_path in tqdm(zip(train_image_paths[:10], test_image_paths[:10])):\n",
    "    train_image = Image.open(train_path).convert('RGB')\n",
    "    test_image = Image.open(test_path).convert('RGB')\n",
    "\n",
    "    detected_face = facial_detection.detect_face(train_image)\n",
    "\n",
    "    embedding = tuple(facial_detection.get_facial_embeddings(detected_face).numpy().reshape(-1))\n",
    "\n",
    "    train_embeddings.append(embedding)\n",
    "    train_data[embedding] = train_path.split('/')[-1]\n",
    "\n",
    "    detected_face = facial_detection.detect_face(test_image)\n",
    "    embedding = tuple(facial_detection.get_facial_embeddings(detected_face).numpy().reshape(-1))\n",
    "    test_embeddings.append(embedding)\n",
    "    ground_truth[embedding] = train_path.split('/')[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('image_0001.png', 'image_0001.png')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[test_embeddings[0]], train_data[train_embeddings[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LSHash' object has no attribute 'buckets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m embedding \u001b[38;5;129;01min\u001b[39;00m train_embeddings:\n\u001b[1;32m     13\u001b[0m     db\u001b[38;5;241m.\u001b[39madd_entry(embedding, train_data[embedding])\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bucket \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlsh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuckets\u001b[49m:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBucket:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# Print all items in the bucket\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LSHash' object has no attribute 'buckets'"
     ]
    }
   ],
   "source": [
    "from database.db import Database\n",
    "import time\n",
    "\n",
    "# dist -> searchmethod -> (speed, accuracy)\n",
    "collected_metrics = {}\n",
    "\n",
    "# collect speed and accuracy for each search method\n",
    "for dist_func in ['euclidean','cosine']:\n",
    "    for search_method in ['lsh','vector_compression','linear']:\n",
    "        db = Database(search_method, dist_func)\n",
    "\n",
    "        for embedding in train_embeddings:\n",
    "            db.add_entry(embedding, train_data[embedding])\n",
    "\n",
    "        for bucket in db.lsh.:\n",
    "            print(\"Bucket:\")\n",
    "            # Print all items in the bucket\n",
    "            for item in bucket:\n",
    "                print(\"   Embedding:\", item[0])  # Embedding\n",
    "                print(\"   Extra data:\", item[1])  # Extra data (if provided during indexing)\n",
    "\n",
    "        correct = 0\n",
    "        start_time = time.time()\n",
    "        for embedding in test_embeddings:\n",
    "            result = db.query_entry(embedding)\n",
    "            print(result)\n",
    "\n",
    "            if result == ground_truth[embedding]:\n",
    "                correct+=1\n",
    "\n",
    "        end_time = time.time()\n",
    "        collected_metrics[dist_func]={search_method: (len(test_embeddings)/(end_time-start_time), correct/len(test_embeddings))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make bar plots for each metric\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "speeds = [collected_metrics[method][0] for method in collected_metrics]\n",
    "accuracies = [collected_metrics[method][1] for method in collected_metrics]\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,5))\n",
    "ax[0].bar(collected_metrics.keys(), speeds)\n",
    "ax[0].set_title('Speeds')\n",
    "ax[0].set_ylabel('Images per second')\n",
    "ax[1].bar(collected_metrics.keys(), accuracies)\n",
    "ax[1].set_title('Accuracies')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intelligent_sn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
